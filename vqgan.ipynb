{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11698521,"sourceType":"datasetVersion","datasetId":7342832}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nfrom torchvision.utils import save_image\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T09:21:00.139657Z","iopub.execute_input":"2025-05-06T09:21:00.140299Z","iopub.status.idle":"2025-05-06T09:21:06.343744Z","shell.execute_reply.started":"2025-05-06T09:21:00.140265Z","shell.execute_reply":"2025-05-06T09:21:06.342986Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Set random seed for reproducibility\ntorch.manual_seed(42)\n\n# Define the Vector Quantizer\nclass VectorQuantizer(nn.Module):\n    def __init__(self, num_embeddings, embedding_dim, commitment_cost):\n        super(VectorQuantizer, self).__init__()\n        \n        self.num_embeddings = num_embeddings  # Size of the codebook\n        self.embedding_dim = embedding_dim    # Dimension of each codebook vector\n        self.commitment_cost = commitment_cost  # Weight for commitment loss\n        \n        # Create the codebook as a learnable parameter\n        # This is our \"visual vocabulary\"\n        self.codebook = nn.Embedding(num_embeddings, embedding_dim)\n        self.codebook.weight.data.uniform_(-1/num_embeddings, 1/num_embeddings)\n        \n    def forward(self, inputs):\n        # Convert inputs from BCHW -> BHWC\n        inputs = inputs.permute(0, 2, 3, 1).contiguous()\n        input_shape = inputs.shape\n        \n        # Flatten input\n        flat_input = inputs.view(-1, self.embedding_dim)\n        \n        # Calculate distances between input vectors and codebook vectors\n        # For each input vector, find the closest codebook entry\n        distances = torch.sum(flat_input**2, dim=1, keepdim=True) + \\\n                    torch.sum(self.codebook.weight**2, dim=1) - \\\n                    2 * torch.matmul(flat_input, self.codebook.weight.t())\n        \n        # Find nearest encoding\n        encoding_indices = torch.argmin(distances, dim=1).unsqueeze(1)\n        encodings = torch.zeros(encoding_indices.shape[0], self.num_embeddings, device=inputs.device)\n        encodings.scatter_(1, encoding_indices, 1)\n        \n        # Quantize and unflatten\n        quantized = torch.matmul(encodings, self.codebook.weight).view(input_shape)\n        \n        # Calculate loss\n        e_latent_loss = F.mse_loss(quantized.detach(), inputs)  # Encoder loss\n        q_latent_loss = F.mse_loss(quantized, inputs.detach())  # Codebook loss\n        loss = q_latent_loss + self.commitment_cost * e_latent_loss\n        \n        # Straight-through estimator\n        quantized = inputs + (quantized - inputs).detach()\n        \n        # Convert quantized from BHWC -> BCHW\n        quantized = quantized.permute(0, 3, 1, 2).contiguous()\n        \n        return quantized, loss, encoding_indices.view(input_shape[:-1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T09:21:06.345010Z","iopub.execute_input":"2025-05-06T09:21:06.345853Z","iopub.status.idle":"2025-05-06T09:21:06.357261Z","shell.execute_reply.started":"2025-05-06T09:21:06.345832Z","shell.execute_reply":"2025-05-06T09:21:06.356646Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Define the Encoder\nclass Encoder(nn.Module):\n    def __init__(self, in_channels, hidden_dims, embedding_dim):\n        super(Encoder, self).__init__()\n        \n        modules = []\n        \n        # Simple convolutional architecture\n        for h_dim in hidden_dims:\n            modules.append(\n                nn.Sequential(\n                    nn.Conv2d(in_channels, out_channels=h_dim,\n                              kernel_size=3, stride=2, padding=1),\n                    nn.BatchNorm2d(h_dim),\n                    nn.LeakyReLU()\n                )\n            )\n            in_channels = h_dim\n        \n        # Final layer\n        modules.append(\n            nn.Sequential(\n                nn.Conv2d(in_channels, embedding_dim,\n                          kernel_size=1, stride=1),\n                nn.BatchNorm2d(embedding_dim)\n            )\n        )\n        \n        self.encoder = nn.Sequential(*modules)\n        \n    def forward(self, x):\n        encoding = self.encoder(x)\n        # Store the spatial(HxW) dimensions for the decoder\n        self.output_dims = encoding.shape[2:]\n        return encoding","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T09:21:06.357842Z","iopub.execute_input":"2025-05-06T09:21:06.358071Z","iopub.status.idle":"2025-05-06T09:21:06.368165Z","shell.execute_reply.started":"2025-05-06T09:21:06.358054Z","shell.execute_reply":"2025-05-06T09:21:06.367457Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Define the Decoder\nclass Decoder(nn.Module):\n    def __init__(self, embedding_dim, hidden_dims, out_channels):\n        super(Decoder, self).__init__()\n        \n        modules = []\n        \n        # Initial layer - no upsampling yet\n        modules.append(\n            nn.Sequential(\n                nn.Conv2d(embedding_dim, hidden_dims[-1],\n                          kernel_size=3, stride=1, padding=1),\n                nn.BatchNorm2d(hidden_dims[-1]),\n                nn.LeakyReLU()\n            )\n        )\n        \n        # Upsampling layers\n        for i in range(len(hidden_dims) - 1, 0, -1):\n            modules.append(\n                nn.Sequential(\n                    # Ensure proper upsampling with output_padding when needed\n                    nn.ConvTranspose2d(hidden_dims[i], hidden_dims[i-1],\n                                      kernel_size=3, stride=2, padding=1, output_padding=1),\n                    nn.BatchNorm2d(hidden_dims[i-1]),\n                    nn.LeakyReLU()\n                )\n            )\n        \n        # Final layer\n        modules.append(\n            nn.Sequential(\n                nn.ConvTranspose2d(hidden_dims[0], out_channels,\n                                  kernel_size=3, stride=2, padding=1, output_padding=1),\n                nn.Tanh()\n            )\n        )\n        \n        self.decoder = nn.Sequential(*modules)\n        \n    def forward(self, x):\n        return self.decoder(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T09:21:06.369362Z","iopub.execute_input":"2025-05-06T09:21:06.369546Z","iopub.status.idle":"2025-05-06T09:21:06.385305Z","shell.execute_reply.started":"2025-05-06T09:21:06.369531Z","shell.execute_reply":"2025-05-06T09:21:06.384623Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Define the Discriminator for GAN component\nclass Discriminator(nn.Module):\n    def __init__(self, in_channels, hidden_dims):\n        super(Discriminator, self).__init__()\n        \n        modules = []\n        \n        # Simple convolutional architecture\n        for h_dim in hidden_dims:\n            modules.append(\n                nn.Sequential(\n                    nn.Conv2d(in_channels, out_channels=h_dim,\n                              kernel_size=4, stride=2, padding=1),\n                    nn.BatchNorm2d(h_dim),\n                    nn.LeakyReLU(0.2)\n                )\n            )\n            in_channels = h_dim\n        \n        # Final layer\n        modules.append(\n            nn.Sequential(\n                nn.Conv2d(in_channels, 1,\n                          kernel_size=3, stride=1, padding=0),\n                nn.Sigmoid()\n            )\n        )\n        \n        self.discriminator = nn.Sequential(*modules)\n        \n    def forward(self, x):\n        return self.discriminator(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T09:21:06.386050Z","iopub.execute_input":"2025-05-06T09:21:06.386277Z","iopub.status.idle":"2025-05-06T09:21:06.400239Z","shell.execute_reply.started":"2025-05-06T09:21:06.386257Z","shell.execute_reply":"2025-05-06T09:21:06.399576Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Define the complete VQGAN model\nclass VQGAN(nn.Module):\n    def __init__(self, in_channels, hidden_dims, num_embeddings, embedding_dim, commitment_cost, img_size=28):\n        super(VQGAN, self).__init__()\n        \n        self.encoder = Encoder(in_channels, hidden_dims, embedding_dim)\n        self.vector_quantizer = VectorQuantizer(num_embeddings, embedding_dim, commitment_cost)\n        self.decoder = Decoder(embedding_dim, hidden_dims, in_channels)\n        self.discriminator = Discriminator(in_channels, hidden_dims)\n        \n    def forward(self, x):\n        # Store original size for resizing output if needed\n        original_size = x.shape[2:]\n        \n        z = self.encoder(x)\n        quantized, vq_loss, encoding_indices = self.vector_quantizer(z)\n        x_recon = self.decoder(quantized)\n        \n        # Ensure output size matches input size\n        if x_recon.shape[2:] != original_size:\n            x_recon = F.interpolate(x_recon, size=original_size, mode='bilinear', align_corners=False)\n            \n        return x_recon, vq_loss, encoding_indices\n    \n    def encode(self, x):\n        z = self.encoder(x)\n        quantized, _, encoding_indices = self.vector_quantizer(z)\n        return encoding_indices\n    \n    def decode(self, encoding_indices):\n        # Convert indices to one-hot encodings\n        encodings = F.one_hot(encoding_indices, self.vector_quantizer.num_embeddings).float()\n        \n        # Get quantized vectors from the codebook\n        quantized = torch.matmul(encodings, self.vector_quantizer.codebook.weight)\n        \n        # Reshape to match the encoder output shape\n        quantized = quantized.permute(0, 3, 1, 2).contiguous()\n        \n        # Decode\n        x_recon = self.decoder(quantized)\n\n        if x_recon.shape[2:] != (self.img_size, self.img_size):\n            x_recon = F.interpolate(x_recon, size=(self.img_size, self.img_size), \n                                   mode='bilinear', align_corners=False)\n        return x_recon","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T09:21:12.065122Z","iopub.execute_input":"2025-05-06T09:21:12.065390Z","iopub.status.idle":"2025-05-06T09:21:12.073108Z","shell.execute_reply.started":"2025-05-06T09:21:12.065362Z","shell.execute_reply":"2025-05-06T09:21:12.072268Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Function to train the model\ndef train_vqgan(model, dataloader, num_epochs=10, learning_rate=1e-4):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = model.to(device)\n\n    # Optimizers\n    optimizer = optim.Adam(\n        list(model.encoder.parameters()) +\n        list(model.decoder.parameters()) +\n        list(model.vector_quantizer.parameters()), lr=learning_rate)\n\n    disc_optimizer = optim.Adam(model.discriminator.parameters(), lr=learning_rate * 0.5)  # slower LR for D\n\n    # Loss functions\n    recon_loss_fn = nn.MSELoss()\n    gan_loss_fn = nn.BCELoss()\n\n    # Loss weights\n    recon_loss_weight = 1.0\n    vq_loss_weight = 1.0\n    gan_loss_weight = 0.1\n\n    for epoch in range(num_epochs):\n        model.train()\n        total_g_loss = 0\n        total_d_loss = 0\n\n        for batch_idx, (data, _) in enumerate(dataloader):\n            data = data.to(device)\n\n            ### ----- Train Generator -----\n            optimizer.zero_grad()\n            reconstructions, vq_loss, _ = model(data)\n\n            # Loss components\n            recon_loss = recon_loss_fn(reconstructions, data)\n            disc_fake = model.discriminator(reconstructions)\n            real_labels = torch.full_like(disc_fake, 0.9)  # label smoothing\n            gan_loss = gan_loss_fn(disc_fake, real_labels)\n\n            # Combined generator loss\n            g_loss = (recon_loss_weight * recon_loss +\n                      vq_loss_weight * vq_loss +\n                      gan_loss_weight * gan_loss)\n\n            g_loss.backward()\n            optimizer.step()\n\n            ### ----- Train Discriminator every 2 steps -----\n            if batch_idx % 2 == 0:\n                disc_optimizer.zero_grad()\n\n                disc_real = model.discriminator(data)\n                disc_fake = model.discriminator(reconstructions.detach())\n\n                real_labels = torch.full_like(disc_real, 0.9)\n                fake_labels = torch.full_like(disc_fake, 0.1)\n\n                d_real_loss = gan_loss_fn(disc_real, real_labels)\n                d_fake_loss = gan_loss_fn(disc_fake, fake_labels)\n                d_loss = (d_real_loss + d_fake_loss) / 2\n\n                d_loss.backward()\n                disc_optimizer.step()\n            else:\n                d_loss = torch.tensor(0.0)  # placeholder if D not trained\n\n            total_g_loss += g_loss.item()\n            total_d_loss += d_loss.item()\n\n            if batch_idx % 100 == 0:\n                print(f\"Epoch: {epoch}, Batch: {batch_idx}, \"\n                      f\"G Loss: {g_loss.item():.4f} \"\n                      f\"(Recon: {recon_loss.item():.4f}, VQ: {vq_loss.item():.4f}, GAN: {gan_loss.item():.4f}), \"\n                      f\"D Loss: {d_loss.item():.4f}\")\n\n        avg_g_loss = total_g_loss / len(dataloader)\n        avg_d_loss = total_d_loss / (len(dataloader) // 2)\n        print(f\"Epoch: {epoch}, Avg G Loss: {avg_g_loss:.4f}, Avg D Loss: {avg_d_loss:.4f}\")\n\n        # Save some reconstructed images\n        if epoch % 5 == 0:\n            model.eval()\n            with torch.no_grad():\n                sample = next(iter(dataloader))[0][:8].to(device)\n                recon, _, _ = model(sample)\n                comparison = torch.cat([sample, recon], dim=0)\n                save_image(comparison.cpu(), f'reconstruction_epoch_{epoch}.png', nrow=8)\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T09:33:48.806795Z","iopub.execute_input":"2025-05-06T09:33:48.807135Z","iopub.status.idle":"2025-05-06T09:33:48.820322Z","shell.execute_reply.started":"2025-05-06T09:33:48.807107Z","shell.execute_reply":"2025-05-06T09:33:48.819588Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Main function to set up and run the training\ndef main():\n    # Set up parameters\n    batch_size = 64\n    hidden_dims = [32, 64, 128]\n    num_embeddings = 512  # Size of the codebook\n    embedding_dim = 64    # Dimension of each codebook vector\n    commitment_cost = 0.25\n    num_epochs = 20\n    img_size = 28\n    \n    # Load the MNIST dataset for simplicity\n    transform = transforms.Compose([\n        transforms.Resize((img_size, img_size)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5,), (0.5,))\n    ])\n    \n    train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n    \n    # Initialize the model\n    model = VQGAN(in_channels=1,  # MNIST is grayscale\n                  hidden_dims=hidden_dims,\n                  num_embeddings=num_embeddings,\n                  embedding_dim=embedding_dim,\n                  commitment_cost=commitment_cost,\n                  img_size=img_size)\n    \n    # Train the model\n    trained_model = train_vqgan(model, train_loader, num_epochs=num_epochs)\n    \n    # Save the model\n    torch.save(trained_model.state_dict(), 'vqgan_mnist.pth')\n    \n    # Generate some samples\n    trained_model.eval()\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # Visualize some reconstructions\n    with torch.no_grad():\n        sample = next(iter(train_loader))[0][:16].to(device)\n        recon, _, _ = trained_model(sample)\n        \n        # Create a figure to visualize\n        fig, axes = plt.subplots(4, 8, figsize=(16, 8))\n        \n        # Display original images\n        for i in range(16):\n            ax = axes[i // 8, i % 8]\n            ax.imshow(sample[i].cpu().numpy().squeeze(), cmap='gray')\n            ax.axis('off')\n            if i == 0:\n                ax.set_title('Original')\n        \n        # Display reconstructed images\n        for i in range(16):\n            ax = axes[2 + i // 8, i % 8]\n            ax.imshow(recon[i].cpu().numpy().squeeze(), cmap='gray')\n            ax.axis('off')\n            if i == 0:\n                ax.set_title('Reconstructed')\n        \n        plt.tight_layout()\n        plt.savefig('vqgan_samples.png')\n        plt.close()\n    \n    # Visualize the codebook\n    with torch.no_grad():\n        # Get the codebook\n        codebook = trained_model.vector_quantizer.codebook.weight.data\n        \n        # Create a grid to visualize some codebook entries\n        grid_size = min(16, num_embeddings)\n        fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n        \n        for i in range(grid_size):\n            ax = axes[i // 4, i % 4]\n            # Reshape the embedding to a square for visualization\n            size = int(np.sqrt(embedding_dim))\n            code = codebook[i].reshape(size, size).cpu().numpy()\n            ax.imshow(code, cmap='viridis')\n            ax.axis('off')\n            ax.set_title(f'Code {i}')\n        \n        plt.tight_layout()\n        plt.savefig('codebook_visualization.png')\n        plt.close()\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T09:33:50.317738Z","iopub.execute_input":"2025-05-06T09:33:50.318030Z","iopub.status.idle":"2025-05-06T09:38:01.772601Z","shell.execute_reply.started":"2025-05-06T09:33:50.318010Z","shell.execute_reply":"2025-05-06T09:38:01.771783Z"}},"outputs":[{"name":"stdout","text":"Epoch: 0, Batch: 0, G Loss: 2.2119 (Recon: 0.8977, VQ: 1.2489, GAN: 0.6519), D Loss: 0.7599\nEpoch: 0, Batch: 100, G Loss: 1.6617 (Recon: 0.3602, VQ: 1.2404, GAN: 0.6110), D Loss: 0.8998\nEpoch: 0, Batch: 200, G Loss: 1.5646 (Recon: 0.2811, VQ: 1.2280, GAN: 0.5552), D Loss: 0.8844\nEpoch: 0, Batch: 300, G Loss: 1.5184 (Recon: 0.2352, VQ: 1.2186, GAN: 0.6458), D Loss: 0.7975\nEpoch: 0, Batch: 400, G Loss: 1.4697 (Recon: 0.1927, VQ: 1.2123, GAN: 0.6477), D Loss: 0.7323\nEpoch: 0, Batch: 500, G Loss: 1.4599 (Recon: 0.1825, VQ: 1.2070, GAN: 0.7039), D Loss: 0.7066\nEpoch: 0, Batch: 600, G Loss: 1.4543 (Recon: 0.1755, VQ: 1.2049, GAN: 0.7390), D Loss: 0.6692\nEpoch: 0, Batch: 700, G Loss: 1.4458 (Recon: 0.1680, VQ: 1.2036, GAN: 0.7416), D Loss: 0.6640\nEpoch: 0, Batch: 800, G Loss: 1.4451 (Recon: 0.1702, VQ: 1.2022, GAN: 0.7268), D Loss: 0.6553\nEpoch: 0, Batch: 900, G Loss: 1.4422 (Recon: 0.1655, VQ: 1.2020, GAN: 0.7462), D Loss: 0.6522\nEpoch: 0, Avg G Loss: 1.5187, Avg D Loss: 0.7434\nEpoch: 1, Batch: 0, G Loss: 1.4400 (Recon: 0.1613, VQ: 1.2017, GAN: 0.7699), D Loss: 0.6464\nEpoch: 1, Batch: 100, G Loss: 1.4388 (Recon: 0.1615, VQ: 1.2037, GAN: 0.7357), D Loss: 0.6664\nEpoch: 1, Batch: 200, G Loss: 1.4374 (Recon: 0.1598, VQ: 1.2034, GAN: 0.7427), D Loss: 0.6443\nEpoch: 1, Batch: 300, G Loss: 1.4336 (Recon: 0.1583, VQ: 1.2041, GAN: 0.7124), D Loss: 0.6747\nEpoch: 1, Batch: 400, G Loss: 1.4186 (Recon: 0.1427, VQ: 1.2036, GAN: 0.7222), D Loss: 0.6597\nEpoch: 1, Batch: 500, G Loss: 1.4248 (Recon: 0.1428, VQ: 1.2066, GAN: 0.7537), D Loss: 0.6656\nEpoch: 1, Batch: 600, G Loss: 1.4275 (Recon: 0.1461, VQ: 1.2077, GAN: 0.7378), D Loss: 0.6528\nEpoch: 1, Batch: 700, G Loss: 1.4298 (Recon: 0.1511, VQ: 1.2082, GAN: 0.7055), D Loss: 0.7154\nEpoch: 1, Batch: 800, G Loss: 1.4285 (Recon: 0.1458, VQ: 1.2079, GAN: 0.7479), D Loss: 0.6655\nEpoch: 1, Batch: 900, G Loss: 1.4325 (Recon: 0.1544, VQ: 1.2065, GAN: 0.7164), D Loss: 0.6615\nEpoch: 1, Avg G Loss: 1.4315, Avg D Loss: 0.6643\nEpoch: 2, Batch: 0, G Loss: 1.4263 (Recon: 0.1417, VQ: 1.2091, GAN: 0.7547), D Loss: 0.6653\nEpoch: 2, Batch: 100, G Loss: 1.4240 (Recon: 0.1427, VQ: 1.2087, GAN: 0.7262), D Loss: 0.6594\nEpoch: 2, Batch: 200, G Loss: 1.4154 (Recon: 0.1402, VQ: 1.2058, GAN: 0.6933), D Loss: 0.6870\nEpoch: 2, Batch: 300, G Loss: 1.4268 (Recon: 0.1470, VQ: 1.2067, GAN: 0.7313), D Loss: 0.6773\nEpoch: 2, Batch: 400, G Loss: 1.4272 (Recon: 0.1435, VQ: 1.2095, GAN: 0.7428), D Loss: 0.6251\nEpoch: 2, Batch: 500, G Loss: 1.4103 (Recon: 0.1270, VQ: 1.2059, GAN: 0.7735), D Loss: 0.6674\nEpoch: 2, Batch: 600, G Loss: 1.4174 (Recon: 0.1359, VQ: 1.2084, GAN: 0.7310), D Loss: 0.6745\nEpoch: 2, Batch: 700, G Loss: 1.4290 (Recon: 0.1456, VQ: 1.2085, GAN: 0.7493), D Loss: 0.6900\nEpoch: 2, Batch: 800, G Loss: 1.4273 (Recon: 0.1442, VQ: 1.2102, GAN: 0.7284), D Loss: 0.6512\nEpoch: 2, Batch: 900, G Loss: 1.4249 (Recon: 0.1374, VQ: 1.2100, GAN: 0.7758), D Loss: 0.6374\nEpoch: 2, Avg G Loss: 1.4203, Avg D Loss: 0.6625\nEpoch: 3, Batch: 0, G Loss: 1.4209 (Recon: 0.1331, VQ: 1.2102, GAN: 0.7761), D Loss: 0.6572\nEpoch: 3, Batch: 100, G Loss: 1.4191 (Recon: 0.1394, VQ: 1.2077, GAN: 0.7204), D Loss: 0.6428\nEpoch: 3, Batch: 200, G Loss: 1.4192 (Recon: 0.1384, VQ: 1.2050, GAN: 0.7581), D Loss: 0.6547\nEpoch: 3, Batch: 300, G Loss: 1.4306 (Recon: 0.1427, VQ: 1.2117, GAN: 0.7625), D Loss: 0.6313\nEpoch: 3, Batch: 400, G Loss: 1.4200 (Recon: 0.1396, VQ: 1.2081, GAN: 0.7233), D Loss: 0.6523\nEpoch: 3, Batch: 500, G Loss: 1.4151 (Recon: 0.1378, VQ: 1.2032, GAN: 0.7399), D Loss: 0.6249\nEpoch: 3, Batch: 600, G Loss: 1.4201 (Recon: 0.1318, VQ: 1.2079, GAN: 0.8045), D Loss: 0.6347\nEpoch: 3, Batch: 700, G Loss: 1.4230 (Recon: 0.1388, VQ: 1.2092, GAN: 0.7498), D Loss: 0.6466\nEpoch: 3, Batch: 800, G Loss: 1.4102 (Recon: 0.1198, VQ: 1.2070, GAN: 0.8338), D Loss: 0.6525\nEpoch: 3, Batch: 900, G Loss: 1.4198 (Recon: 0.1265, VQ: 1.2093, GAN: 0.8410), D Loss: 0.5978\nEpoch: 3, Avg G Loss: 1.4158, Avg D Loss: 0.6403\nEpoch: 4, Batch: 0, G Loss: 1.4048 (Recon: 0.1203, VQ: 1.2062, GAN: 0.7834), D Loss: 0.6326\nEpoch: 4, Batch: 100, G Loss: 1.4196 (Recon: 0.1190, VQ: 1.2131, GAN: 0.8749), D Loss: 0.6009\nEpoch: 4, Batch: 200, G Loss: 1.4094 (Recon: 0.1249, VQ: 1.2029, GAN: 0.8161), D Loss: 0.5929\nEpoch: 4, Batch: 300, G Loss: 1.4282 (Recon: 0.1330, VQ: 1.2066, GAN: 0.8857), D Loss: 0.6192\nEpoch: 4, Batch: 400, G Loss: 1.4037 (Recon: 0.1232, VQ: 1.1997, GAN: 0.8085), D Loss: 0.5902\nEpoch: 4, Batch: 500, G Loss: 1.4132 (Recon: 0.1275, VQ: 1.2031, GAN: 0.8253), D Loss: 0.6251\nEpoch: 4, Batch: 600, G Loss: 1.4277 (Recon: 0.1420, VQ: 1.1994, GAN: 0.8627), D Loss: 0.5842\nEpoch: 4, Batch: 700, G Loss: 1.4305 (Recon: 0.1349, VQ: 1.2051, GAN: 0.9053), D Loss: 0.6145\nEpoch: 4, Batch: 800, G Loss: 1.4210 (Recon: 0.1301, VQ: 1.2015, GAN: 0.8939), D Loss: 0.5977\nEpoch: 4, Batch: 900, G Loss: 1.4141 (Recon: 0.1305, VQ: 1.2043, GAN: 0.7921), D Loss: 0.5781\nEpoch: 4, Avg G Loss: 1.4146, Avg D Loss: 0.6143\nEpoch: 5, Batch: 0, G Loss: 1.4178 (Recon: 0.1269, VQ: 1.2106, GAN: 0.8036), D Loss: 0.5942\nEpoch: 5, Batch: 100, G Loss: 1.4168 (Recon: 0.1179, VQ: 1.2065, GAN: 0.9234), D Loss: 0.5943\nEpoch: 5, Batch: 200, G Loss: 1.4300 (Recon: 0.1229, VQ: 1.2091, GAN: 0.9792), D Loss: 0.5861\nEpoch: 5, Batch: 300, G Loss: 1.4054 (Recon: 0.1237, VQ: 1.2090, GAN: 0.7283), D Loss: 0.6021\nEpoch: 5, Batch: 400, G Loss: 1.4337 (Recon: 0.1358, VQ: 1.2087, GAN: 0.8911), D Loss: 0.6090\nEpoch: 5, Batch: 500, G Loss: 1.4156 (Recon: 0.1217, VQ: 1.2065, GAN: 0.8747), D Loss: 0.6034\nEpoch: 5, Batch: 600, G Loss: 1.4223 (Recon: 0.1259, VQ: 1.2074, GAN: 0.8901), D Loss: 0.5966\nEpoch: 5, Batch: 700, G Loss: 1.4126 (Recon: 0.1175, VQ: 1.2007, GAN: 0.9437), D Loss: 0.5670\nEpoch: 5, Batch: 800, G Loss: 1.4362 (Recon: 0.1351, VQ: 1.2129, GAN: 0.8821), D Loss: 0.5965\nEpoch: 5, Batch: 900, G Loss: 1.4328 (Recon: 0.1325, VQ: 1.2147, GAN: 0.8558), D Loss: 0.6074\nEpoch: 5, Avg G Loss: 1.4225, Avg D Loss: 0.5934\nEpoch: 6, Batch: 0, G Loss: 1.4304 (Recon: 0.1316, VQ: 1.2153, GAN: 0.8350), D Loss: 0.5903\nEpoch: 6, Batch: 100, G Loss: 1.4223 (Recon: 0.1253, VQ: 1.2119, GAN: 0.8512), D Loss: 0.6088\nEpoch: 6, Batch: 200, G Loss: 1.4352 (Recon: 0.1325, VQ: 1.2121, GAN: 0.9059), D Loss: 0.5735\nEpoch: 6, Batch: 300, G Loss: 1.4285 (Recon: 0.1183, VQ: 1.2182, GAN: 0.9205), D Loss: 0.5356\nEpoch: 6, Batch: 400, G Loss: 1.4343 (Recon: 0.1244, VQ: 1.2209, GAN: 0.8894), D Loss: 0.5782\nEpoch: 6, Batch: 500, G Loss: 1.4352 (Recon: 0.1339, VQ: 1.2213, GAN: 0.7992), D Loss: 0.6194\nEpoch: 6, Batch: 600, G Loss: 1.4441 (Recon: 0.1172, VQ: 1.2339, GAN: 0.9304), D Loss: 0.5775\nEpoch: 6, Batch: 700, G Loss: 1.4313 (Recon: 0.1231, VQ: 1.2192, GAN: 0.8896), D Loss: 0.5955\nEpoch: 6, Batch: 800, G Loss: 1.4259 (Recon: 0.1227, VQ: 1.2155, GAN: 0.8764), D Loss: 0.5508\nEpoch: 6, Batch: 900, G Loss: 1.4447 (Recon: 0.1288, VQ: 1.2277, GAN: 0.8822), D Loss: 0.6026\nEpoch: 6, Avg G Loss: 1.4343, Avg D Loss: 0.5833\nEpoch: 7, Batch: 0, G Loss: 1.4345 (Recon: 0.1251, VQ: 1.2167, GAN: 0.9277), D Loss: 0.5692\nEpoch: 7, Batch: 100, G Loss: 1.4329 (Recon: 0.1263, VQ: 1.2180, GAN: 0.8856), D Loss: 0.5788\nEpoch: 7, Batch: 200, G Loss: 1.4225 (Recon: 0.1093, VQ: 1.2247, GAN: 0.8846), D Loss: 0.5355\nEpoch: 7, Batch: 300, G Loss: 1.4367 (Recon: 0.1132, VQ: 1.2280, GAN: 0.9551), D Loss: 0.5429\nEpoch: 7, Batch: 400, G Loss: 1.4412 (Recon: 0.1328, VQ: 1.2256, GAN: 0.8284), D Loss: 0.5840\nEpoch: 7, Batch: 500, G Loss: 1.4445 (Recon: 0.1229, VQ: 1.2281, GAN: 0.9345), D Loss: 0.5406\nEpoch: 7, Batch: 600, G Loss: 1.4631 (Recon: 0.1240, VQ: 1.2274, GAN: 1.1165), D Loss: 0.6056\nEpoch: 7, Batch: 700, G Loss: 1.4404 (Recon: 0.1299, VQ: 1.2228, GAN: 0.8763), D Loss: 0.5883\nEpoch: 7, Batch: 800, G Loss: 1.4552 (Recon: 0.1315, VQ: 1.2418, GAN: 0.8196), D Loss: 0.5543\nEpoch: 7, Batch: 900, G Loss: 1.4196 (Recon: 0.1266, VQ: 1.2186, GAN: 0.7439), D Loss: 0.5950\nEpoch: 7, Avg G Loss: 1.4404, Avg D Loss: 0.5701\nEpoch: 8, Batch: 0, G Loss: 1.4271 (Recon: 0.1206, VQ: 1.2210, GAN: 0.8548), D Loss: 0.6238\nEpoch: 8, Batch: 100, G Loss: 1.4338 (Recon: 0.1300, VQ: 1.2174, GAN: 0.8641), D Loss: 0.5691\nEpoch: 8, Batch: 200, G Loss: 1.4265 (Recon: 0.1182, VQ: 1.2226, GAN: 0.8566), D Loss: 0.5865\nEpoch: 8, Batch: 300, G Loss: 1.4582 (Recon: 0.1304, VQ: 1.2269, GAN: 1.0100), D Loss: 0.5348\nEpoch: 8, Batch: 400, G Loss: 1.4519 (Recon: 0.1255, VQ: 1.2323, GAN: 0.9412), D Loss: 0.5210\nEpoch: 8, Batch: 500, G Loss: 1.4169 (Recon: 0.1160, VQ: 1.2190, GAN: 0.8180), D Loss: 0.5975\nEpoch: 8, Batch: 600, G Loss: 1.4478 (Recon: 0.1196, VQ: 1.2179, GAN: 1.1031), D Loss: 0.5517\nEpoch: 8, Batch: 700, G Loss: 1.4249 (Recon: 0.1302, VQ: 1.2095, GAN: 0.8518), D Loss: 0.5695\nEpoch: 8, Batch: 800, G Loss: 1.4275 (Recon: 0.1216, VQ: 1.2119, GAN: 0.9403), D Loss: 0.5819\nEpoch: 8, Batch: 900, G Loss: 1.4269 (Recon: 0.1192, VQ: 1.2264, GAN: 0.8131), D Loss: 0.5466\nEpoch: 8, Avg G Loss: 1.4388, Avg D Loss: 0.5657\nEpoch: 9, Batch: 0, G Loss: 1.4515 (Recon: 0.1177, VQ: 1.2089, GAN: 1.2488), D Loss: 0.5874\nEpoch: 9, Batch: 100, G Loss: 1.4512 (Recon: 0.1224, VQ: 1.2279, GAN: 1.0088), D Loss: 0.5470\nEpoch: 9, Batch: 200, G Loss: 1.4106 (Recon: 0.1182, VQ: 1.2004, GAN: 0.9200), D Loss: 0.5458\nEpoch: 9, Batch: 300, G Loss: 1.4457 (Recon: 0.1271, VQ: 1.2281, GAN: 0.9054), D Loss: 0.5304\nEpoch: 9, Batch: 400, G Loss: 1.4286 (Recon: 0.1160, VQ: 1.2083, GAN: 1.0436), D Loss: 0.5276\nEpoch: 9, Batch: 500, G Loss: 1.4313 (Recon: 0.1206, VQ: 1.2223, GAN: 0.8835), D Loss: 0.5299\nEpoch: 9, Batch: 600, G Loss: 1.4287 (Recon: 0.1188, VQ: 1.2045, GAN: 1.0550), D Loss: 0.5425\nEpoch: 9, Batch: 700, G Loss: 1.4436 (Recon: 0.1250, VQ: 1.2250, GAN: 0.9359), D Loss: 0.5722\nEpoch: 9, Batch: 800, G Loss: 1.4385 (Recon: 0.1197, VQ: 1.2155, GAN: 1.0324), D Loss: 0.5362\nEpoch: 9, Batch: 900, G Loss: 1.4505 (Recon: 0.1255, VQ: 1.2118, GAN: 1.1320), D Loss: 0.4941\nEpoch: 9, Avg G Loss: 1.4276, Avg D Loss: 0.5471\nEpoch: 10, Batch: 0, G Loss: 1.4087 (Recon: 0.1175, VQ: 1.2028, GAN: 0.8841), D Loss: 0.5429\nEpoch: 10, Batch: 100, G Loss: 1.4422 (Recon: 0.1254, VQ: 1.1979, GAN: 1.1884), D Loss: 0.5318\nEpoch: 10, Batch: 200, G Loss: 1.4068 (Recon: 0.1181, VQ: 1.1907, GAN: 0.9803), D Loss: 0.5464\nEpoch: 10, Batch: 300, G Loss: 1.4046 (Recon: 0.1255, VQ: 1.1690, GAN: 1.1011), D Loss: 0.5714\nEpoch: 10, Batch: 400, G Loss: 1.3758 (Recon: 0.1193, VQ: 1.1640, GAN: 0.9255), D Loss: 0.5610\nEpoch: 10, Batch: 500, G Loss: 1.4209 (Recon: 0.1219, VQ: 1.1848, GAN: 1.1419), D Loss: 0.5908\nEpoch: 10, Batch: 600, G Loss: 1.3767 (Recon: 0.1195, VQ: 1.1533, GAN: 1.0391), D Loss: 0.5271\nEpoch: 10, Batch: 700, G Loss: 1.3934 (Recon: 0.1235, VQ: 1.1674, GAN: 1.0252), D Loss: 0.5384\nEpoch: 10, Batch: 800, G Loss: 1.3605 (Recon: 0.1142, VQ: 1.1483, GAN: 0.9797), D Loss: 0.5208\nEpoch: 10, Batch: 900, G Loss: 1.3711 (Recon: 0.1224, VQ: 1.1633, GAN: 0.8536), D Loss: 0.5482\nEpoch: 10, Avg G Loss: 1.3997, Avg D Loss: 0.5380\nEpoch: 11, Batch: 0, G Loss: 1.3861 (Recon: 0.1338, VQ: 1.1605, GAN: 0.9186), D Loss: 0.5203\nEpoch: 11, Batch: 100, G Loss: 1.3879 (Recon: 0.1250, VQ: 1.1624, GAN: 1.0051), D Loss: 0.5289\nEpoch: 11, Batch: 200, G Loss: 1.3527 (Recon: 0.1133, VQ: 1.1245, GAN: 1.1500), D Loss: 0.5184\nEpoch: 11, Batch: 300, G Loss: 1.3602 (Recon: 0.1126, VQ: 1.1270, GAN: 1.2065), D Loss: 0.5328\nEpoch: 11, Batch: 400, G Loss: 1.3650 (Recon: 0.1192, VQ: 1.1325, GAN: 1.1324), D Loss: 0.5122\nEpoch: 11, Batch: 500, G Loss: 1.3588 (Recon: 0.1239, VQ: 1.1428, GAN: 0.9206), D Loss: 0.5053\nEpoch: 11, Batch: 600, G Loss: 1.3340 (Recon: 0.1199, VQ: 1.1199, GAN: 0.9414), D Loss: 0.5828\nEpoch: 11, Batch: 700, G Loss: 1.3638 (Recon: 0.1239, VQ: 1.1333, GAN: 1.0654), D Loss: 0.4748\nEpoch: 11, Batch: 800, G Loss: 1.3274 (Recon: 0.1120, VQ: 1.0993, GAN: 1.1616), D Loss: 0.5200\nEpoch: 11, Batch: 900, G Loss: 1.3227 (Recon: 0.1299, VQ: 1.1105, GAN: 0.8236), D Loss: 0.5245\nEpoch: 11, Avg G Loss: 1.3526, Avg D Loss: 0.5255\nEpoch: 12, Batch: 0, G Loss: 1.3168 (Recon: 0.1241, VQ: 1.0934, GAN: 0.9930), D Loss: 0.5211\nEpoch: 12, Batch: 100, G Loss: 1.3153 (Recon: 0.1168, VQ: 1.1033, GAN: 0.9526), D Loss: 0.5220\nEpoch: 12, Batch: 200, G Loss: 1.3348 (Recon: 0.1251, VQ: 1.0932, GAN: 1.1642), D Loss: 0.5535\nEpoch: 12, Batch: 300, G Loss: 1.3204 (Recon: 0.1220, VQ: 1.0775, GAN: 1.2092), D Loss: 0.4966\nEpoch: 12, Batch: 400, G Loss: 1.2938 (Recon: 0.1245, VQ: 1.0672, GAN: 1.0208), D Loss: 0.4961\nEpoch: 12, Batch: 500, G Loss: 1.2815 (Recon: 0.1172, VQ: 1.0682, GAN: 0.9600), D Loss: 0.5213\nEpoch: 12, Batch: 600, G Loss: 1.2836 (Recon: 0.1156, VQ: 1.0497, GAN: 1.1821), D Loss: 0.5154\nEpoch: 12, Batch: 700, G Loss: 1.2754 (Recon: 0.1226, VQ: 1.0424, GAN: 1.1037), D Loss: 0.5001\nEpoch: 12, Batch: 800, G Loss: 1.2585 (Recon: 0.1227, VQ: 1.0353, GAN: 1.0047), D Loss: 0.5172\nEpoch: 12, Batch: 900, G Loss: 1.2873 (Recon: 0.1219, VQ: 1.0432, GAN: 1.2227), D Loss: 0.5012\nEpoch: 12, Avg G Loss: 1.2960, Avg D Loss: 0.5147\nEpoch: 13, Batch: 0, G Loss: 1.2961 (Recon: 0.1231, VQ: 1.0441, GAN: 1.2892), D Loss: 0.4750\nEpoch: 13, Batch: 100, G Loss: 1.2220 (Recon: 0.1138, VQ: 1.0159, GAN: 0.9229), D Loss: 0.5308\nEpoch: 13, Batch: 200, G Loss: 1.2853 (Recon: 0.1248, VQ: 1.0382, GAN: 1.2236), D Loss: 0.4900\nEpoch: 13, Batch: 300, G Loss: 1.2122 (Recon: 0.1152, VQ: 1.0063, GAN: 0.9067), D Loss: 0.5276\nEpoch: 13, Batch: 400, G Loss: 1.2216 (Recon: 0.1117, VQ: 0.9888, GAN: 1.2103), D Loss: 0.5378\nEpoch: 13, Batch: 500, G Loss: 1.2340 (Recon: 0.1236, VQ: 1.0137, GAN: 0.9669), D Loss: 0.5246\nEpoch: 13, Batch: 600, G Loss: 1.1936 (Recon: 0.1117, VQ: 0.9777, GAN: 1.0414), D Loss: 0.4964\nEpoch: 13, Batch: 700, G Loss: 1.1901 (Recon: 0.1186, VQ: 0.9789, GAN: 0.9263), D Loss: 0.5113\nEpoch: 13, Batch: 800, G Loss: 1.1709 (Recon: 0.1160, VQ: 0.9674, GAN: 0.8748), D Loss: 0.5002\nEpoch: 13, Batch: 900, G Loss: 1.1966 (Recon: 0.1229, VQ: 0.9675, GAN: 1.0621), D Loss: 0.4840\nEpoch: 13, Avg G Loss: 1.2346, Avg D Loss: 0.5073\nEpoch: 14, Batch: 0, G Loss: 1.2108 (Recon: 0.1230, VQ: 0.9768, GAN: 1.1097), D Loss: 0.4860\nEpoch: 14, Batch: 100, G Loss: 1.1871 (Recon: 0.1174, VQ: 0.9547, GAN: 1.1506), D Loss: 0.4849\nEpoch: 14, Batch: 200, G Loss: 1.1975 (Recon: 0.1204, VQ: 0.9515, GAN: 1.2563), D Loss: 0.5180\nEpoch: 14, Batch: 300, G Loss: 1.1776 (Recon: 0.1157, VQ: 0.9587, GAN: 1.0314), D Loss: 0.4749\nEpoch: 14, Batch: 400, G Loss: 1.1307 (Recon: 0.1181, VQ: 0.9278, GAN: 0.8476), D Loss: 0.5338\nEpoch: 14, Batch: 500, G Loss: 1.1916 (Recon: 0.1200, VQ: 0.9540, GAN: 1.1764), D Loss: 0.5081\nEpoch: 14, Batch: 600, G Loss: 1.1459 (Recon: 0.1186, VQ: 0.9185, GAN: 1.0871), D Loss: 0.4910\nEpoch: 14, Batch: 700, G Loss: 1.1587 (Recon: 0.1149, VQ: 0.9100, GAN: 1.3382), D Loss: 0.5186\nEpoch: 14, Batch: 800, G Loss: 1.1638 (Recon: 0.1216, VQ: 0.9271, GAN: 1.1516), D Loss: 0.4990\nEpoch: 14, Batch: 900, G Loss: 1.1340 (Recon: 0.1167, VQ: 0.9164, GAN: 1.0090), D Loss: 0.5137\nEpoch: 14, Avg G Loss: 1.1728, Avg D Loss: 0.5024\nEpoch: 15, Batch: 0, G Loss: 1.1592 (Recon: 0.1157, VQ: 0.9064, GAN: 1.3712), D Loss: 0.4551\nEpoch: 15, Batch: 100, G Loss: 1.1980 (Recon: 0.1274, VQ: 0.9254, GAN: 1.4518), D Loss: 0.5326\nEpoch: 15, Batch: 200, G Loss: 1.1292 (Recon: 0.1130, VQ: 0.9127, GAN: 1.0361), D Loss: 0.4829\nEpoch: 15, Batch: 300, G Loss: 1.1496 (Recon: 0.1245, VQ: 0.8938, GAN: 1.3138), D Loss: 0.4709\nEpoch: 15, Batch: 400, G Loss: 1.1919 (Recon: 0.1229, VQ: 0.9401, GAN: 1.2892), D Loss: 0.4620\nEpoch: 15, Batch: 500, G Loss: 1.1171 (Recon: 0.1141, VQ: 0.8797, GAN: 1.2326), D Loss: 0.4881\nEpoch: 15, Batch: 600, G Loss: 1.1350 (Recon: 0.1209, VQ: 0.8858, GAN: 1.2829), D Loss: 0.5057\nEpoch: 15, Batch: 700, G Loss: 1.0705 (Recon: 0.1120, VQ: 0.8592, GAN: 0.9923), D Loss: 0.4856\nEpoch: 15, Batch: 800, G Loss: 1.0740 (Recon: 0.1208, VQ: 0.8744, GAN: 0.7884), D Loss: 0.5305\nEpoch: 15, Batch: 900, G Loss: 1.1101 (Recon: 0.1245, VQ: 0.8728, GAN: 1.1277), D Loss: 0.4932\nEpoch: 15, Avg G Loss: 1.1268, Avg D Loss: 0.4933\nEpoch: 16, Batch: 0, G Loss: 1.1206 (Recon: 0.1207, VQ: 0.8848, GAN: 1.1510), D Loss: 0.4912\nEpoch: 16, Batch: 100, G Loss: 1.0855 (Recon: 0.1171, VQ: 0.8741, GAN: 0.9436), D Loss: 0.5009\nEpoch: 16, Batch: 200, G Loss: 1.0772 (Recon: 0.1225, VQ: 0.8702, GAN: 0.8453), D Loss: 0.5172\nEpoch: 16, Batch: 300, G Loss: 1.1528 (Recon: 0.1259, VQ: 0.8907, GAN: 1.3620), D Loss: 0.4555\nEpoch: 16, Batch: 400, G Loss: 1.0618 (Recon: 0.1148, VQ: 0.8592, GAN: 0.8783), D Loss: 0.5322\nEpoch: 16, Batch: 500, G Loss: 1.1122 (Recon: 0.1194, VQ: 0.8578, GAN: 1.3511), D Loss: 0.4811\nEpoch: 16, Batch: 600, G Loss: 1.1132 (Recon: 0.1163, VQ: 0.8606, GAN: 1.3619), D Loss: 0.5014\nEpoch: 16, Batch: 700, G Loss: 1.0771 (Recon: 0.1188, VQ: 0.8539, GAN: 1.0443), D Loss: 0.4960\nEpoch: 16, Batch: 800, G Loss: 1.0625 (Recon: 0.1172, VQ: 0.8355, GAN: 1.0974), D Loss: 0.4525\nEpoch: 16, Batch: 900, G Loss: 1.0979 (Recon: 0.1236, VQ: 0.8641, GAN: 1.1013), D Loss: 0.4663\nEpoch: 16, Avg G Loss: 1.1003, Avg D Loss: 0.4867\nEpoch: 17, Batch: 0, G Loss: 1.0742 (Recon: 0.1229, VQ: 0.8386, GAN: 1.1273), D Loss: 0.4698\nEpoch: 17, Batch: 100, G Loss: 1.0528 (Recon: 0.1202, VQ: 0.8455, GAN: 0.8709), D Loss: 0.5033\nEpoch: 17, Batch: 200, G Loss: 1.0423 (Recon: 0.1219, VQ: 0.8409, GAN: 0.7953), D Loss: 0.5258\nEpoch: 17, Batch: 300, G Loss: 1.0760 (Recon: 0.1196, VQ: 0.8321, GAN: 1.2430), D Loss: 0.5050\nEpoch: 17, Batch: 400, G Loss: 1.1074 (Recon: 0.1286, VQ: 0.8359, GAN: 1.4288), D Loss: 0.4531\nEpoch: 17, Batch: 500, G Loss: 1.0747 (Recon: 0.1222, VQ: 0.8437, GAN: 1.0872), D Loss: 0.5610\nEpoch: 17, Batch: 600, G Loss: 1.0103 (Recon: 0.1108, VQ: 0.7916, GAN: 1.0786), D Loss: 0.4677\nEpoch: 17, Batch: 700, G Loss: 1.0804 (Recon: 0.1285, VQ: 0.8556, GAN: 0.9628), D Loss: 0.4824\nEpoch: 17, Batch: 800, G Loss: 1.0440 (Recon: 0.1199, VQ: 0.8321, GAN: 0.9198), D Loss: 0.5140\nEpoch: 17, Batch: 900, G Loss: 1.1177 (Recon: 0.1299, VQ: 0.8385, GAN: 1.4931), D Loss: 0.4183\nEpoch: 17, Avg G Loss: 1.0757, Avg D Loss: 0.4819\nEpoch: 18, Batch: 0, G Loss: 1.0519 (Recon: 0.1272, VQ: 0.8197, GAN: 1.0505), D Loss: 0.4756\nEpoch: 18, Batch: 100, G Loss: 1.0487 (Recon: 0.1156, VQ: 0.7996, GAN: 1.3350), D Loss: 0.4895\nEpoch: 18, Batch: 200, G Loss: 1.0314 (Recon: 0.1205, VQ: 0.8053, GAN: 1.0565), D Loss: 0.4886\nEpoch: 18, Batch: 300, G Loss: 1.0499 (Recon: 0.1207, VQ: 0.8050, GAN: 1.2419), D Loss: 0.4563\nEpoch: 18, Batch: 400, G Loss: 1.0233 (Recon: 0.1119, VQ: 0.7981, GAN: 1.1338), D Loss: 0.4585\nEpoch: 18, Batch: 500, G Loss: 1.0602 (Recon: 0.1201, VQ: 0.8014, GAN: 1.3864), D Loss: 0.4997\nEpoch: 18, Batch: 600, G Loss: 1.0774 (Recon: 0.1216, VQ: 0.8077, GAN: 1.4814), D Loss: 0.5397\nEpoch: 18, Batch: 700, G Loss: 1.0695 (Recon: 0.1295, VQ: 0.8162, GAN: 1.2377), D Loss: 0.4672\nEpoch: 18, Batch: 800, G Loss: 1.0727 (Recon: 0.1198, VQ: 0.8044, GAN: 1.4852), D Loss: 0.4140\nEpoch: 18, Batch: 900, G Loss: 0.9933 (Recon: 0.1145, VQ: 0.7742, GAN: 1.0463), D Loss: 0.4825\nEpoch: 18, Avg G Loss: 1.0495, Avg D Loss: 0.4862\nEpoch: 19, Batch: 0, G Loss: 1.0708 (Recon: 0.1256, VQ: 0.8137, GAN: 1.3150), D Loss: 0.5044\nEpoch: 19, Batch: 100, G Loss: 1.0314 (Recon: 0.1330, VQ: 0.7778, GAN: 1.2063), D Loss: 0.5185\nEpoch: 19, Batch: 200, G Loss: 1.0653 (Recon: 0.1288, VQ: 0.8147, GAN: 1.2184), D Loss: 0.4505\nEpoch: 19, Batch: 300, G Loss: 1.0032 (Recon: 0.1192, VQ: 0.7805, GAN: 1.0349), D Loss: 0.4891\nEpoch: 19, Batch: 400, G Loss: 1.0530 (Recon: 0.1263, VQ: 0.7985, GAN: 1.2821), D Loss: 0.4953\nEpoch: 19, Batch: 500, G Loss: 1.0833 (Recon: 0.1232, VQ: 0.7929, GAN: 1.6716), D Loss: 0.5352\nEpoch: 19, Batch: 600, G Loss: 0.9913 (Recon: 0.1210, VQ: 0.7733, GAN: 0.9700), D Loss: 0.4955\nEpoch: 19, Batch: 700, G Loss: 1.0760 (Recon: 0.1235, VQ: 0.7934, GAN: 1.5901), D Loss: 0.5244\nEpoch: 19, Batch: 800, G Loss: 1.0378 (Recon: 0.1184, VQ: 0.7859, GAN: 1.3355), D Loss: 0.4907\nEpoch: 19, Batch: 900, G Loss: 1.0524 (Recon: 0.1194, VQ: 0.7957, GAN: 1.3731), D Loss: 0.4951\nEpoch: 19, Avg G Loss: 1.0340, Avg D Loss: 0.4800\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"model = VQGAN(in_channels=1, hidden_dims=[32, 64, 128],\n              num_embeddings=512, embedding_dim=64,\n              commitment_cost=0.25, img_size=28)\n\nmodel.load_state_dict(torch.load('vqgan_mnist.pth'))\nmodel.eval()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T09:49:34.128559Z","iopub.execute_input":"2025-05-06T09:49:34.129321Z","iopub.status.idle":"2025-05-06T09:49:34.162921Z","shell.execute_reply.started":"2025-05-06T09:49:34.129295Z","shell.execute_reply":"2025-05-06T09:49:34.162304Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/3149222259.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('vqgan_mnist.pth'))\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"VQGAN(\n  (encoder): Encoder(\n    (encoder): Sequential(\n      (0): Sequential(\n        (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): LeakyReLU(negative_slope=0.01)\n      )\n      (1): Sequential(\n        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): LeakyReLU(negative_slope=0.01)\n      )\n      (2): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): LeakyReLU(negative_slope=0.01)\n      )\n      (3): Sequential(\n        (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (vector_quantizer): VectorQuantizer(\n    (codebook): Embedding(512, 64)\n  )\n  (decoder): Decoder(\n    (decoder): Sequential(\n      (0): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): LeakyReLU(negative_slope=0.01)\n      )\n      (1): Sequential(\n        (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): LeakyReLU(negative_slope=0.01)\n      )\n      (2): Sequential(\n        (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): LeakyReLU(negative_slope=0.01)\n      )\n      (3): Sequential(\n        (0): ConvTranspose2d(32, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n        (1): Tanh()\n      )\n    )\n  )\n  (discriminator): Discriminator(\n    (discriminator): Sequential(\n      (0): Sequential(\n        (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): LeakyReLU(negative_slope=0.2)\n      )\n      (1): Sequential(\n        (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): LeakyReLU(negative_slope=0.2)\n      )\n      (2): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): LeakyReLU(negative_slope=0.2)\n      )\n      (3): Sequential(\n        (0): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1))\n        (1): Sigmoid()\n      )\n    )\n  )\n)"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"from PIL import Image\nfrom torchvision import transforms\n\n# Load image\nimg_path = '/kaggle/input/image-try/Example-of-a-MNIST-input-An-image-is-passed-to-the-network-as-a-matrix-of-28-by-28.png'  # Make sure it's a grayscale 28x28 image\nimage = Image.open(img_path).convert('L')  # Convert to grayscale\n\n# Apply the same transforms used during training\ntransform = transforms.Compose([\n    transforms.Resize((28, 28)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\ninput_tensor = transform(image).unsqueeze(0).to(device)  # Add batch dimension\ninput_tensor.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T09:52:17.153643Z","iopub.execute_input":"2025-05-06T09:52:17.154287Z","iopub.status.idle":"2025-05-06T09:52:17.167829Z","shell.execute_reply.started":"2025-05-06T09:52:17.154256Z","shell.execute_reply":"2025-05-06T09:52:17.167167Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 1, 28, 28])"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"with torch.no_grad():\n    reconstructed, _, _ = model(input_tensor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T09:52:23.778332Z","iopub.execute_input":"2025-05-06T09:52:23.779077Z","iopub.status.idle":"2025-05-06T09:52:23.791396Z","shell.execute_reply.started":"2025-05-06T09:52:23.779051Z","shell.execute_reply":"2025-05-06T09:52:23.790702Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(1, 2, figsize=(6, 3))\n\n# Original\nax[0].imshow(input_tensor.squeeze().cpu().numpy(), cmap='gray')\nax[0].set_title('Original')\nax[0].axis('off')\n\n# Reconstructed\nax[1].imshow(reconstructed.squeeze().cpu().numpy(), cmap='gray')\nax[1].set_title('Reconstructed')\nax[1].axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T09:52:31.062402Z","iopub.execute_input":"2025-05-06T09:52:31.062690Z","iopub.status.idle":"2025-05-06T09:52:31.200692Z","shell.execute_reply.started":"2025-05-06T09:52:31.062658Z","shell.execute_reply":"2025-05-06T09:52:31.200023Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 600x300 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}